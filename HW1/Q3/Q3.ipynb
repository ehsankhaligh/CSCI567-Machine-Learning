{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e1ca726-8d6e-4c5e-bd8c-31ddc9a6bf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f083302-99cd-47c0-8a75-c331e3029736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(data):\n",
    "\ttrain_set, valid_set, test_set = data['train_data'], data['val_data'], data['test_data']\n",
    "\tXtrain = train_set[\"features\"]\n",
    "\tytrain = train_set[\"labels\"]\n",
    "\tXval = valid_set[\"features\"]\n",
    "\tyval = valid_set[\"labels\"]\n",
    "\tXtest = test_set[\"features\"]\n",
    "\tytest = test_set[\"labels\"]\n",
    "\n",
    "\tXtrain = np.array(Xtrain)\n",
    "\tXval = np.array(Xval)\n",
    "\tXtest = np.array(Xtest)\n",
    "\n",
    "\tytrain = np.array(ytrain)\n",
    "\tyval = np.array(yval)\n",
    "\tytest = np.array(ytest)\n",
    "\t\n",
    "\treturn Xtrain, ytrain, Xval, yval, Xtest, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af428b65-072a-4efa-9dcc-22a676993202",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing_with_transformation(data, do_minmax_scaling=True, do_normalization=False):\n",
    "    train_set, valid_set, test_set = data['train_data'], data['val_data'], data['test_data']\n",
    "    Xtrain = train_set[\"features\"]\n",
    "    ytrain = train_set[\"labels\"]\n",
    "    Xval = valid_set[\"features\"]\n",
    "    yval = valid_set[\"labels\"]\n",
    "    Xtest = test_set[\"features\"]\n",
    "    ytest = test_set[\"labels\"]\n",
    "    \n",
    "    Xtrain = np.array(Xtrain)\n",
    "    Xval = np.array(Xval)\n",
    "    Xtest = np.array(Xtest)\n",
    "    \n",
    "    ytrain = np.array(ytrain)\n",
    "    yval = np.array(yval)\n",
    "    ytest = np.array(ytest)\n",
    "    \n",
    "    # We load data from json here and turn the data into numpy array\n",
    "    # You can further perform data transformation on Xtrain, Xval, Xtest\n",
    "\n",
    "    def minmax_scaling(X):\n",
    "    \n",
    "        #####################################################\n",
    "        #\t\t\t\t YOUR CODE HERE\t\t\t\t\t    #\n",
    "        \n",
    "        # Reference: https://numpy.org/doc/stable/reference/generated/numpy.matrix.transpose.html\n",
    "        transposed_X = X.transpose()\n",
    "        \n",
    "        # Min-max scaling for each feature\n",
    "        for i, feature in enumerate(transposed_X):\n",
    "            min_val = np.min(feature)\n",
    "            max_val = np.max(feature)\n",
    "        \n",
    "            # Interpolates linearly so each value in the feature vector \n",
    "            # falls between 0 and 1, inclusively\n",
    "            feature_new = (feature - min_val) / (max_val - min_val)\n",
    "            transposed_X[i] = feature_new\n",
    "        \n",
    "        X = transposed_X.transpose()\n",
    "        \n",
    "        return X\n",
    "    \n",
    "        #####################################################\n",
    "\n",
    "\n",
    "    # Min-Max scaling\n",
    "    if do_minmax_scaling:\n",
    "    \n",
    "    #####################################################\n",
    "    #\t\t\t\t YOUR CODE HERE\t\t\t\t\t    #\n",
    "        Xtrain = minmax_scaling(Xtrain)\n",
    "        Xval = minmax_scaling(Xval)\n",
    "        Xtest = minmax_scaling(Xtest)\n",
    "    \n",
    "    #####################################################\n",
    "    \n",
    "    # Normalization\n",
    "    def normalization(X):\n",
    "    #####################################################\n",
    "    #\t\t\t\t YOUR CODE HERE\t\t\t\t\t    #\n",
    "    \n",
    "        # Reference: https://numpy.org/doc/stable/reference/generated/numpy.linalg.norm.html\n",
    "        for i, x in enumerate(X):\n",
    "            norm = np.linalg.norm(x)\n",
    "            normalized_x = np.divide(x, norm)\n",
    "            X[i] = normalized_x\n",
    "    \n",
    "    #####################################################\n",
    "    \n",
    "        return X\n",
    "\n",
    "    \n",
    "    if do_normalization:\n",
    "        Xtrain = normalization(Xtrain)\n",
    "        Xval = normalization(Xval)\n",
    "        Xtest = normalization(Xtest)\n",
    "\n",
    "    return Xtrain, ytrain, Xval, yval, Xtest, ytest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4b17c2a-cdf6-4704-b7fc-e24051c7fe78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_l2_distances(Xtrain, X):\n",
    "\t\"\"\"\n",
    "\tCompute the distance between each test point in X and each training point\n",
    "\tin Xtrain.\n",
    "\tInputs:\n",
    "\t- Xtrain: A numpy array of shape (num_train, D) containing training data\n",
    "\t- X: A numpy array of shape (num_test, D) containing test data.\n",
    "\tReturns:\n",
    "\t- dists: A numpy array of shape (num_test, num_train) where dists[i, j]\n",
    "\t  is the Euclidean distance between the ith test point and the jth training\n",
    "\t  point.\n",
    "\t\"\"\"\n",
    "    #####################################################\n",
    "\t#\t\t\t\t YOUR CODE HERE\t\t\t\t\t    #\n",
    "\n",
    "\tnum_test = X.shape[0]\n",
    "\tnum_train = Xtrain.shape[0]\n",
    "\n",
    "\tdists = np.empty((num_test, num_train))\n",
    "\n",
    "\tfor i in range(num_test):\n",
    "\t\tfor j in range(num_train):\n",
    "\t\t\tdiffs = X[i] - Xtrain[j]\n",
    "\t\t\tsquared_diffs = np.square(diffs)\n",
    "\t\t\tdists[i][j] = np.sqrt(np.sum(squared_diffs))\n",
    "    #####################################################\t\n",
    "    \n",
    "\treturn dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f7fb746-9833-4b59-8518-d749322baf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_distances(Xtrain, X):\n",
    "    \"\"\"\n",
    "    Compute the distance between each test point in X and each training point\n",
    "    in Xtrain.\n",
    "    Inputs:\n",
    "    - Xtrain: A numpy array of shape (num_train, D) containing training data\n",
    "    - X: A numpy array of shape (num_test, D) containing test data.\n",
    "    Returns:\n",
    "    - dists: A numpy array of shape (num_test, num_train) where dists[i, j]\n",
    "    is the Cosine distance between the ith test point and the jth training\n",
    "    point.\n",
    "    \"\"\"\n",
    "    #####################################################\n",
    "    #\t\t\t\t YOUR CODE HERE\t\t\t\t\t    #\n",
    "    \n",
    "    num_test = X.shape[0]\n",
    "    num_train = Xtrain.shape[0]\n",
    "\n",
    "    dists = np.empty((num_test, num_train))\n",
    "\n",
    "    for i in range(num_test):\n",
    "        for j in range(num_train):\n",
    "            \n",
    "            dot_product_x_xprime = np.dot(X[i], Xtrain[j])\n",
    "            norm_x = np.linalg.norm(X[i])\n",
    "            norm_xprime = np.linalg.norm(Xtrain[j])\n",
    "\n",
    "            # Check for zero norm to avoid division by zero\n",
    "            if norm_x == 0 or norm_xprime == 0:\n",
    "                dists[i, j] = 1\n",
    "            else:\n",
    "                dists[i, j] = 1 - (dot_product_x_xprime / (norm_x * norm_xprime))\n",
    "\n",
    "    #####################################################\n",
    "    return dists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "400e490e-881f-4285-a4c9-6dabe1bfe63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels(k, ytrain, dists):\n",
    "    \"\"\"\n",
    "    Given a matrix of distances between test points and training points,\n",
    "    predict a label for each test point.\n",
    "    Inputs:\n",
    "    - k: The number of nearest neighbors used for prediction.\n",
    "    - ytrain: A numpy array of shape (num_train,) where ytrain[i] is the label\n",
    "      of the ith training point.\n",
    "    - dists: A numpy array of shape (num_test, num_train) where dists[i, j]\n",
    "      gives the distance betwen the ith test point and the jth training point.\n",
    "    Returns:\n",
    "    - ypred: A numpy array of shape (num_test,) containing predicted labels for the\n",
    "      test data, where y[i] is the predicted label for the test point X[i].\n",
    "    \"\"\"\n",
    "    #####################################################\n",
    "    #\t\t\t\t YOUR CODE HERE\t\t\t\t\t    #\n",
    "    num_test = dists.shape[0]\n",
    "    \n",
    "    # Reference: https://numpy.org/doc/stable/reference/generated/numpy.zeros.html\n",
    "    ypred = np.zeros(num_test)\n",
    "    \n",
    "    for i in range(num_test):\n",
    "        # Sort based on distances\n",
    "        dist_label_pairs = zip(dists[i], ytrain)\n",
    "        first_k_dist = sorted(dist_label_pairs, key=lambda x: x[0])[:k]\n",
    "    \n",
    "        # Count occurrences of each label in the k-nearest neighbors\n",
    "        label_counts = Counter([x[1] for x in first_k_dist])\n",
    "    \n",
    "        # Predict the label based on the majority vote\n",
    "        if label_counts[1] > (k // 2):\n",
    "            ypred[i] = 1\n",
    "    #####################################################\n",
    "    \n",
    "    return ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14da3f29-0086-491f-a59c-3cd6f529217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error_rate(y, ypred):\n",
    "\t\"\"\"\n",
    "\tCompute the error rate of prediction based on the true labels.\n",
    "\tInputs:\n",
    "\t- y: A numpy array with of shape (num_test,) where y[i] is the true label\n",
    "\t  of the ith test point.\n",
    "\t- ypred: A numpy array with of shape (num_test,) where ypred[i] is the\n",
    "\t  prediction of the ith test point.\n",
    "\tReturns:\n",
    "\t- err: The error rate of prediction (scalar).\n",
    "\t\"\"\"\n",
    "\t#####################################################\n",
    "\t#\t\t\t\t YOUR CODE HERE\t\t\t\t\t    #\n",
    "\tnum_test = y.shape[0]\n",
    "\n",
    "\t# Counts wrongly classified data point\n",
    "\ttotal_mismatches = 0\n",
    "\tfor i in range(num_test):\n",
    "\t\tif y[i] != ypred[i]:\n",
    "\t\t\ttotal_mismatches += 1\n",
    "\n",
    "\terr = total_mismatches / num_test\n",
    "    #####################################################\n",
    "\n",
    "\treturn err\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3d1eb47-6590-4e8c-ad9d-a90fb075adf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_k(K, ytrain, dists, yval):\n",
    "    \"\"\"\n",
    "    Find best k according to validation error rate.\n",
    "    Inputs:\n",
    "    - K: A list of ks.\n",
    "    - ytrain: A numpy array of shape (num_train,) where ytrain[i] is the label\n",
    "    of the ith training point.\n",
    "    - dists: A numpy array of shape (num_test, num_train) where dists[i, j]\n",
    "    is the distance between the ith test point and the jth training\n",
    "    point.\n",
    "    - yval: A numpy array with of shape (num_val,) where y[i] is the true label\n",
    "    of the ith validation point.\n",
    "    Returns:\n",
    "    - best_k: The k with the lowest error rate.\n",
    "    - validation_error: A list of error rate of different ks in K.\n",
    "    - best_err: The lowest error rate we get from all ks in K.\n",
    "    \"\"\"\n",
    "    #####################################################\n",
    "    #\t\t\t\t YOUR CODE HERE\t\t\t\t\t    #\n",
    "    best_k = None\n",
    "    best_err = float('inf') #do not set to none, it fails in below condition comparison \n",
    "    validation_error = []\n",
    "    \n",
    "    for k in K:\n",
    "        ypred = predict_labels(k, ytrain, dists)\n",
    "        error_rate = compute_error_rate(yval, ypred)\n",
    "        validation_error.append(error_rate)\n",
    "    \n",
    "        if error_rate < best_err:\n",
    "            best_err = error_rate\n",
    "            best_k = k\n",
    "    #####################################################\n",
    "    return best_k, validation_error, best_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24acf026-b4b7-4588-b9bf-eb5969433827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validation error rate is 0.07692307692307693 in Problem Set 1.1\n",
      "\n",
      "The validation error rate is 0.04395604395604396 in Problem Set 1.2 when using normalization\n",
      "\n",
      "The validation error rate is 0.04395604395604396 in Problem Set 1.2 when using minmax_scaling\n",
      "\n",
      "The validation error rate is 0.04395604395604396 in Problem Set 1.3, which use cosine distance\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 91 is out of bounds for axis 0 with size 91",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 134\u001b[0m\n\u001b[1;32m    131\u001b[0m     f\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 134\u001b[0m \t\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 81\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m dists \u001b[38;5;241m=\u001b[39m compute_l2_distances(Xtrain, Xval) \n\u001b[1;32m     80\u001b[0m ypred \u001b[38;5;241m=\u001b[39m predict_labels(k, ytrain, dists)\n\u001b[0;32m---> 81\u001b[0m error_rate \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_error_rate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mytrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mypred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m train_errors\u001b[38;5;241m.\u001b[39mappend(error_rate)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m#Report and draw a curve based on the error rate of your model on the validation set for each k.\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 19\u001b[0m, in \u001b[0;36mcompute_error_rate\u001b[0;34m(y, ypred)\u001b[0m\n\u001b[1;32m     17\u001b[0m total_mismatches \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_test):\n\u001b[0;32m---> 19\u001b[0m \t\u001b[38;5;28;01mif\u001b[39;00m y[i] \u001b[38;5;241m!=\u001b[39m \u001b[43mypred\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m:\n\u001b[1;32m     20\u001b[0m \t\ttotal_mismatches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     22\u001b[0m err \u001b[38;5;241m=\u001b[39m total_mismatches \u001b[38;5;241m/\u001b[39m num_test\n",
      "\u001b[0;31mIndexError\u001b[0m: index 91 is out of bounds for axis 0 with size 91"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    input_file = 'breast_cancer_dataset.json'\n",
    "    output_file = 'knn_output.txt'\n",
    "    \n",
    "    #==================Problem Set 1.1=======================\n",
    "    \n",
    "    with open(input_file) as json_data:\n",
    "        data = json.load(json_data)\n",
    "    \n",
    "    # Compute distance matrix\n",
    "    Xtrain, ytrain, Xval, yval, Xtest, ytest = data_processing(data)\n",
    "    \n",
    "    dists = compute_l2_distances(Xtrain, Xval)\n",
    "    \n",
    "    # Compute validation accuracy when k=4\n",
    "    k = 4\n",
    "    ypred = predict_labels(k, ytrain, dists)\n",
    "    err = compute_error_rate(yval, ypred)\n",
    "    print(\"The validation error rate is\", err, \"in Problem Set 1.1\")\n",
    "    print()\n",
    "\n",
    "    #==================Problem Set 1.2=======================\n",
    "\n",
    "    # Compute distance matrix\n",
    "    Xtrain, ytrain, Xval, yval, Xtest, ytest = data_processing_with_transformation(data, do_minmax_scaling=False, do_normalization=True)\n",
    "    \n",
    "    dists = compute_l2_distances(Xtrain, Xval)\n",
    "    \n",
    "    # Compute validation accuracy when k=4\n",
    "    k = 4\n",
    "    ypred = predict_labels(k, ytrain, dists)\n",
    "    err = compute_error_rate(yval, ypred)\n",
    "    print(\"The validation error rate is\", err, \"in Problem Set 1.2 when using normalization\")\n",
    "    print()\n",
    "    \n",
    "    # Compute distance matrix\n",
    "    Xtrain, ytrain, Xval, yval, Xtest, ytest = data_processing_with_transformation(data, do_minmax_scaling=True, do_normalization=False)\n",
    "    \n",
    "    dists = compute_l2_distances(Xtrain, Xval)\n",
    "    \n",
    "    # Compute validation accuracy when k=4\n",
    "    k = 4\n",
    "    ypred = predict_labels(k, ytrain, dists)\n",
    "    err = compute_error_rate(yval, ypred)\n",
    "    print(\"The validation error rate is\", err, \"in Problem Set 1.2 when using minmax_scaling\")\n",
    "    print()\n",
    "\t\n",
    "    #==================Problem Set 1.3=======================\n",
    "\n",
    "    # Compute distance matrix\n",
    "    Xtrain, ytrain, Xval, yval, Xtest, ytest = data_processing(data)\n",
    "    dists = compute_cosine_distances(Xtrain, Xval)\n",
    "    \n",
    "    # Compute validation accuracy when k=4\n",
    "    k = 4\n",
    "    ypred = predict_labels(k, ytrain, dists)\n",
    "    err = compute_error_rate(yval, ypred)\n",
    "    print(\"The validation error rate is\", err, \"in Problem Set 1.3, which use cosine distance\")\n",
    "    print()\n",
    "\n",
    "    #==================Problem Set 1.4=======================\n",
    "    # Compute distance matrix\n",
    "    Xtrain, ytrain, Xval, yval, Xtest, ytest = data_processing(data)\n",
    "    \n",
    "    #======performance of different k in training set=====\n",
    "    K = [1, 2, 4, 6, 8, 10, 12, 14, 16, 18]\n",
    "    #####################################################\n",
    "    #\t\t\t\t YOUR CODE HERE\t\t\t\t\t    #\n",
    "    train_errors = []\n",
    "    validation_errors = []\n",
    "\n",
    "    # Train and evaluate models for each k\n",
    "    for k in K:\n",
    "\n",
    "       #compute_cosine_distances(Xtrain, X) Compute the distance between each test point in X and each training point in Xtrain.\n",
    "    \n",
    "        # Report and draw a curve based on the error rate of your model on the training set for each k\n",
    "        dists = compute_l2_distances(Xtrain, Xtrain)\n",
    "        ypred = predict_labels(k, ytrain, dists)\n",
    "        error_rate = compute_error_rate(ytrain, ypred)\n",
    "        train_errors.append(error_rate)\n",
    "        \n",
    "        #Report and draw a curve based on the error rate of your model on the validation set for each k.\n",
    "        dists = compute_l2_distances(Xtrain, Xval) \n",
    "        ypred = predict_labels(k, yval, dists)\n",
    "        error_rate = compute_error_rate(yval, ypred)\n",
    "        validation_errors.append(error_rate)\n",
    "    \n",
    "    # Plot the curves\n",
    "    plt.xticks(np.arange(1, 20, 1))\n",
    "    plt.plot(K, train_errors, label='Training Set')\n",
    "    plt.plot(K, validation_errors, label='Validation Set')\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('Error Rate')\n",
    "    plt.title('Error Rate for KNN')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\"\"\n",
    "    (1) Report and draw a curve based on the error rate of your model on the training set for each k. What do you observe? (2pts) \\n\n",
    "\n",
    "    (2) Report and draw a curve based on the error rate of your model on the validation set for each k. What is your best k? (2pts) \\n\n",
    "\n",
    "    (3) What do you observe by comparing the difference between the two curves? (2pts) \\n\n",
    "\n",
    "    (4) What is the final test set error rate you get using your best-k? (1pt) \\n\n",
    "\n",
    "    (5) Comment on these results from the perspective of overfitting, generalization and hyper-parameter tuning. (3pts).\\n\n",
    "\n",
    "          \n",
    "    \"\"\")\n",
    "\n",
    "    #####################################################\n",
    "    \n",
    "    #==========select the best k by using validation set==============\n",
    "    dists = compute_l2_distances(Xtrain, Xval)\n",
    "    best_k, validation_error, best_err = find_best_k(K, ytrain, dists, yval)\n",
    "    \n",
    "    #===============test the performance with your best k=============\n",
    "    dists = compute_l2_distances(Xtrain, Xtest)\n",
    "    ypred = predict_labels(best_k, ytrain, dists)\n",
    "    test_err = compute_error_rate(ytest, ypred)\n",
    "    print(\"In Problem Set 1.4, we use the best k = \", best_k, \"with the best validation error rate\", best_err)\n",
    "    print(\"Using the best k, the final test error rate is\", test_err)\n",
    "    #====================write your results to file===================\n",
    "    f=open(output_file, 'w')\n",
    "    for i in range(len(K)):\n",
    "        f.write('%d %.3f' % (K[i], validation_error[i])+'\\n')\n",
    "        f.write('%s %.3f' % ('test', test_err))\n",
    "    f.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\tmain()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66ccc12-f502-4c80-9bc4-99d934dcba22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
